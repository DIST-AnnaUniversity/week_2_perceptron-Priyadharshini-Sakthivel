{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs [[ 1.   1. ]\n",
      " [-0.5  1. ]\n",
      " [ 3.   1. ]\n",
      " [-2.   1. ]]\n",
      "Teacher values [ 1 -1  1 -1]\n",
      "initial values of weights [0, 0]\n",
      "Training\n",
      "----------\n",
      "1 0 [11.2 11.2]\n",
      "1 1 [16.8  0. ]\n",
      "1 2 [16.8  0. ]\n",
      "1 3 [16.8  0. ]\n",
      "2 0 [16.8  0. ]\n",
      "2 1 [16.8  0. ]\n",
      "2 2 [16.8  0. ]\n",
      "2 3 [16.8  0. ]\n",
      "3 0 [16.8  0. ]\n",
      "3 1 [16.8  0. ]\n",
      "3 2 [16.8  0. ]\n",
      "3 3 [16.8  0. ]\n",
      "4 0 [16.8  0. ]\n",
      "4 1 [16.8  0. ]\n",
      "4 2 [16.8  0. ]\n",
      "4 3 [16.8  0. ]\n",
      "5 0 [16.8  0. ]\n",
      "5 1 [16.8  0. ]\n",
      "5 2 [16.8  0. ]\n",
      "5 3 [16.8  0. ]\n",
      "Final sets of weights:  [16.8  0. ]\n",
      "Testing\n",
      "--------\n",
      "Final output:  [1, -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def perceptron(c,X,d,w,iter):\n",
    "    for n in range(1,iter):\n",
    "        for i, x in enumerate(X):\n",
    "            net = np.dot(X[i],w)\n",
    "            if net > 0:\n",
    "                out = 1\n",
    "            else:\n",
    "                out = -1\n",
    "            r = c*(d[i] - out)\n",
    "            delta_w = r*x\n",
    "            w = delta_w+w\n",
    "            print (n, i, w)\n",
    "    return w\n",
    "def test_perceptron(final_out,X,w):\n",
    "    for i,x in enumerate(X):\n",
    "        net = np.dot(X[i],w)\n",
    "        if net>0:\n",
    "            out = 1\n",
    "        else:\n",
    "            out = -1\n",
    "        final_out = final_out+[out]\n",
    "    return final_out\n",
    "X = np.array([[1,1],[-0.5,1],[3,1],[-2,1],])\n",
    "new_input = np.array([[7,1],[-7,1],])\n",
    "print (\"Inputs\", X)\n",
    "d = np.array([1,-1,1,-1])\n",
    "print (\"Teacher values\", d)\n",
    "w= ([0,0])\n",
    "print (\"initial values of weights\", w)\n",
    "c = 5.6\n",
    "iterations = 6\n",
    "print (\"Training\")\n",
    "print (\"----------\")\n",
    "final_weight = perceptron(c,X,d,w,iterations)\n",
    "print (\"Final sets of weights: \", final_weight)\n",
    "final_out = []\n",
    "print (\"Testing\")\n",
    "print (\"--------\")\n",
    "final_output = test_perceptron(final_out,new_input,final_weight)\n",
    "print (\"Final output: \", final_output)\n",
    "#print (\"Original Teacher values\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs [[ 1.  -2.   0.  -1. ]\n",
      " [ 0.   1.5 -0.5 -1. ]\n",
      " [-1.   1.   0.5 -1. ]]\n",
      "Teacher values [-1 -1  1]\n",
      "initial values of weights [1, -1, 0, 0.5]\n",
      "Training\n",
      "----------\n",
      "Iteration  1\n",
      "--------------\n",
      "Step  0 : [-7.54244148 16.08488296  0.          9.04244148]\n",
      "Step  1 : [-7.54244148  3.18488296  4.3        17.64244148]\n",
      "Step  2 : [-16.14181697  11.78425845   8.59968775   9.04306599]\n",
      "Iteration  2\n",
      "--------------\n",
      "Step  0 : [-16.14181697  11.78425845   8.59968775   9.04306599]\n",
      "Step  1 : [-16.14181697  -1.11352077  12.89894749  17.64158548]\n",
      "Step  2 : [-16.14581853  -1.10951922  12.90094827  17.63758392]\n",
      "Iteration  3\n",
      "--------------\n",
      "Step  0 : [-16.14581853  -1.10951922  12.90094827  17.63758392]\n",
      "Step  1 : [-16.14581853  -1.10951922  12.90094827  17.63758392]\n",
      "Step  2 : [-16.14971739  -1.10562035  12.9028977   17.63368506]\n",
      "Iteration  4\n",
      "--------------\n",
      "Step  0 : [-16.14971739  -1.10562035  12.9028977   17.63368506]\n",
      "Step  1 : [-16.14971739  -1.10562035  12.9028977   17.63368506]\n",
      "Step  2 : [-16.15351873  -1.10181901  12.90479837  17.62988372]\n",
      "Iteration  5\n",
      "--------------\n",
      "Step  0 : [-16.15351873  -1.10181901  12.90479837  17.62988372]\n",
      "Step  1 : [-16.15351873  -1.10181901  12.90479837  17.62988372]\n",
      "Step  2 : [-16.15722734  -1.09811041  12.90665267  17.62617511]\n",
      "Iteration  6\n",
      "--------------\n",
      "Step  0 : [-16.15722734  -1.09811041  12.90665267  17.62617511]\n",
      "Step  1 : [-16.15722734  -1.09811041  12.90665267  17.62617511]\n",
      "Step  2 : [-16.16084765  -1.0944901   12.90846283  17.6225548 ]\n",
      "Iteration  7\n",
      "--------------\n",
      "Step  0 : [-16.16084765  -1.0944901   12.90846283  17.6225548 ]\n",
      "Step  1 : [-16.16084765  -1.0944901   12.90846283  17.6225548 ]\n",
      "Step  2 : [-16.1643838   -1.09095395  12.9102309   17.61901865]\n",
      "Iteration  8\n",
      "--------------\n",
      "Step  0 : [-16.1643838   -1.09095395  12.9102309   17.61901865]\n",
      "Step  1 : [-16.1643838   -1.09095395  12.9102309   17.61901865]\n",
      "Step  2 : [-16.16783962  -1.08749812  12.91195881  17.61556282]\n",
      "Final sets of weights:  [-16.16783962  -1.08749812  12.91195881  17.61556282]\n",
      "Testing\n",
      "--------\n",
      "Final output:  [-1.0, -1.0, 0.9992141636434091]\n",
      "Original Teacher values [-1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "#This program is the implementation of example program of perceptron algorithm from Zurada's Introduction to Artificial Neural networks\n",
    "#This uses continuous activation function\n",
    "import math\n",
    "import numpy as np\n",
    "#/*----------------Function for perceptron algorithm --------------*/\n",
    "def perceptron(c,X,d,w,iter,lam):\n",
    "    for n in range(1,iter):# Number of iterations  = 7\n",
    "        print (\"Iteration \", n)\n",
    "        print (\"--------------\")\n",
    "        for i, x in enumerate(X):\n",
    "            net = np.dot(X[i],w)\n",
    "            out = (2/(1+math.exp(-lam*net)))-1\n",
    "            r = c*(d[i] - out)\n",
    "            delta_w = r*x\n",
    "            w = delta_w+w\n",
    "            print (\"Step \", i, \":\", w)\n",
    "    return w\n",
    "#/*---------------------Function for testing the perceptron-----------*/\n",
    "\n",
    "def test_perceptron(final_out,X,w):\n",
    "    for i,x in enumerate(X):\n",
    "        net = np.dot(X[i],w)\n",
    "        out = (2/(1+math.exp(-lam*net)))-1\n",
    "        final_out = final_out+[out]\n",
    "    return final_out\n",
    "\n",
    "#*---------------Training---------------------------------*/\n",
    "X = np.array([[1,-2,0,-1],[0,1.5,-0.5,-1],[-1,1,0.5,-1],])\n",
    "print (\"Inputs\", X)\n",
    "d = np.array([-1,-1,1])\n",
    "print (\"Teacher values\", d)\n",
    "w= ([1,-1,0,0.5])\n",
    "print (\"initial values of weights\", w)\n",
    "c = 4.3\n",
    "lam = 2#lambda value\n",
    "iterations =9\n",
    "print (\"Training\")\n",
    "print (\"----------\")\n",
    "final_weight = perceptron(c,X,d,w,iterations,lam)\n",
    "print (\"Final sets of weights: \", final_weight)\n",
    "#*-----------------Testing-------------------------------*/\n",
    "final_out = []\n",
    "print (\"Testing\")\n",
    "print (\"--------\")\n",
    "final_output = test_perceptron(final_out,X,final_weight)\n",
    "print (\"Final output: \", final_output)\n",
    "print (\"Original Teacher values\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
